name: Stress Test

on:
  workflow_dispatch:
    inputs:
      duration:
        description: 'Test duration in seconds'
        default: '15'
      concurrency:
        description: 'Number of concurrent workers'
        default: '16'
  pull_request:
    branches: [main]

jobs:
  stress:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'

      - name: Install rclone
        run: |
          curl -sO https://downloads.rclone.org/rclone-current-linux-amd64.zip
          unzip -q rclone-current-linux-amd64.zip
          sudo cp rclone-*-linux-amd64/rclone /usr/local/bin/

      - name: Run stress test
        run: |
          go build -o helmetfs .
          ./helmetfs -addr :8080 -ttl 50ms -upload-ttl 50ms &
          sleep 2

          mkdir -p ~/.config/rclone
          cat > ~/.config/rclone/rclone.conf << 'EOF'
          [helmetfs]
          type = webdav
          url = http://localhost:8080
          vendor = other
          EOF

          DURATION=${{ inputs.duration || '60' }}
          CONCURRENCY=${{ inputs.concurrency || '8' }}
          RESULTS_DIR=$(mktemp -d)

          echo "Running stress test: $CONCURRENCY workers for ${DURATION}s"

          for i in $(seq 1 $CONCURRENCY); do
            (
              WORKER_DIR=$(mktemp -d)
              END_TIME=$(($(date +%s) + DURATION))
              FILES=0
              ERRORS=0

              while [ $(date +%s) -lt $END_TIME ]; do
                FILE="$WORKER_DIR/file-$(date +%s%N).dat"
                dd if=/dev/urandom of="$FILE" bs=1024 count=100 2>/dev/null
                if rclone copy "$FILE" "helmetfs:/stress-$i/" --retries 1 2>/dev/null; then
                  FILES=$((FILES + 1))
                else
                  ERRORS=$((ERRORS + 1))
                fi
                rm -f "$FILE"
              done

              echo "$FILES $ERRORS" > "$RESULTS_DIR/$i"
            ) &
          done
          wait

          # Aggregate results
          TOTAL_FILES=0
          TOTAL_ERRORS=0
          for f in "$RESULTS_DIR"/*; do
            read FILES ERRORS < "$f"
            TOTAL_FILES=$((TOTAL_FILES + FILES))
            TOTAL_ERRORS=$((TOTAL_ERRORS + ERRORS))
            echo "Worker $(basename $f): $FILES files, $ERRORS errors"
          done

          echo "Total: $TOTAL_FILES files, $TOTAL_ERRORS errors"

          # Write job summary
          echo "## Stress Test Results" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "| --- | --- |" >> $GITHUB_STEP_SUMMARY
          echo "| Duration | ${DURATION}s |" >> $GITHUB_STEP_SUMMARY
          echo "| Workers | $CONCURRENCY |" >> $GITHUB_STEP_SUMMARY
          echo "| Files Uploaded | $TOTAL_FILES |" >> $GITHUB_STEP_SUMMARY
          echo "| Errors | $TOTAL_ERRORS |" >> $GITHUB_STEP_SUMMARY

          # Check server health
          if ! curl -sf http://localhost:8080/ > /dev/null; then
            echo "FAIL: Server not responding"
            exit 1
          fi

          # Check error rate
          if [ $TOTAL_FILES -gt 0 ]; then
            ERROR_RATE=$((TOTAL_ERRORS * 100 / TOTAL_FILES))
            echo "Error rate: ${ERROR_RATE}%"
            if [ $ERROR_RATE -gt 10 ]; then
              echo "FAIL: Error rate exceeded 10%"
              exit 1
            fi
          fi

          echo "Stress test passed"

      - name: Cleanup
        if: always()
        run: pkill helmetfs || true
